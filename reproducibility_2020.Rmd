---
title: "Reproducible Science"
subtitle: "Lecture for the BI8040 Logical Modeling Course"
author: "John Zobolas <br/> PhD Student"
institute: "Department of Biology, NTNU"
date: "August 20th, 2020"
output:
  xaringan::moon_reader:
    css: [default, default-fonts, css/ntnu.css, css/my.css, css/title.css]
    self_contained: false
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: macros.js
---

layout: true

<div class="my-footer">
<span>
  <img src="img/ntnu/ntnu-logo-neg.png" style="width:160px;height:30px;">
</span>
</div> 

---

# Outline

.big[
- .blue[Science Tales]
- .red[General Crisis] in Science?
- .green[Reproducibility] via examples
- .purple[Discussion]
]

---

# Science as a Tale

.pull-left[
<img src="https://media.giphy.com/media/KBimavlZz1gHe/giphy.gif" height=450>
]
--
.pull-right.large[
- Great Scientists are like granpas with good old tales!
<br><br>
- Elements of a good story
<br><br>
- Science dissemination (a historical perspective)
<br><br>
- Techonological progress
]

???
- Elements of a good story: **concise, easy to rememeber, carries a central message** that others can carry further on, there is some **magic** to it that captivates you
- Science dissemination has changed: from **text (story)** now we have to present **evidence** (experiments, be it computational or lab) that accompany it (even in Math some proofs are now computational).
- Woods in the fire and taking measurements => experimental evidence!
- Paradigm shift in Science dissemination with techonology's progress has brought more challenges (**Material and Methods in papers, presenting reports**, etc...)
- That has brought a challenge: **experiments that cannot be reproduced are blocking progress**.

---

# Crisis in Science?

.large[Research on Research: **meta-research**]
--

- Most of the proposed associations and/or effects are either .red[False or exaggerated] .purple[Ioannidis (2005&2008)]
- Estimated .red[85%] of research resources are .red[wasted]! .purple[Macleod et. al (2014)]

--

.blue.large[LOTS OF REASONS]:

- Methods not well explained (**desing/analysis/standards flexibility**)   
- Insufficient data sharing (**access policies, resource access**)  
- Results are .red.bold[not reproducible]  
- Lack of collaboration
- Hot scientific field (**Proteus phenomenon**)
- Financial interests and prejudices (**high bias**)
- *P-hacking*, **confirmation and hindsight biases**
- Small sample and effect sizes (**low study power** $1-\beta$)
- **Low pre-study odds** $R$

--

.large[... there is .green[progress] though - how can we can make things better?]

???
- Notice that there are some risk factors associated with FP findings that are immutable, e.g. small effect sizes (**Finding a needle in a haystack**)
- *are either False or exaggerated* => False here means False Positives
- **Advice by Ioannidis (ECCB 2018)**: based on a reproducibility Nature study => read only Nature & Science and cut the results (effect-wise) in half!
- Ioannidis (2005): statistical analysis based on modeling the Framework for False Positive Findings finds the **key factors that make most research findings to be FALSE**: **pre-study odds, bias and study power** (they all relate to **PPV** - prob. of a statistical significant research finding to be TRUE)
- The **Proteus phenomenon** is the tendency in science for early replications of a work to contradict the original findings, a consequence of publication bias and competition.
- **Confirmation bias** (the tendency to focus on evidence that is in line with our expectations or favoured explanation) and **hindsight bias** (the tendency to see an event as having been predictable only after it has occurred) can easily lead us to false conclusions (+ apophenia => see relations in unrelated/random things)
- Claimed Research Findings May Often Be Simply **Accurate Measures of the Prevailing Bias** [Ioannidis2005]
- *Reproducibility Wars*!!!

---

# How to make more published research true?

.larger[*“To make more published research true, practises [should] include the adoption of large-scale collaborative research; replication culture, registration; sharing, reproducibility practices; better statistical methods; standardization of definitions and analyses; more appropriate (usually more stringent) statistical thresholds; and improvement in study design standards, peer review, reporting and dissemination of research and training of the scientific workforce.”*]

.purple[Ioannidis (2014)]

--

- .large[Role of .blue[Stakeholders] (diverse motives)]
- .large[.blue[Research Currencies]: need for a better *Reward system* for Science]

???

- Transparency is superior to trust (reproducibility)
- Peer review is changing: the collective wisdom of the scientific community can be harnessed: **PREPRINTS**
- **Stakeholders** differ in their extent of interest with regards to research results that are **publishable, fundable (money in), translatable, profitable (money out)**.
There are **complex dynamics** between different stakeholders that shape research practices.
Note that a scientist can have many *stakeholding* roles!
- **On Currencies**: Scientists may continue publishing and getting grants (2 key currencies) without making real progress, if **more publications and more grants are all that matters**.
**Academic Hierarchy**: researchers at higher ranks have more papers and more grants.
Sexism, nepotism, cronyism => might also influence academic currencies.
**(High quality) Peer review** is not rewarded.
**Replication** is not rewarded.
- Ioannidis (2014) proposes a table of changes and rewards and discusses what it would mean to have such a paradigm shift in how research is rewarded. 

---

# .small[Top 5 Tips to Make Your Research (Ir)-reproducible!] .tiny.red[a non-exhaustive list!]

.larger[
1. Think “**Big Picture**”
2. Be **abstract**
3. Short and sweet
4. The deficit model
5. **Don't share**
]

--

.larger[.blue[Top Tip]: *“to ensure your work is irreproducible, make sure that you cannot reproduce it yourself”*]

--

.larger[.red[Sad Outcome]: *“After Publishing Research, Irreproducibility Lets False Observations Obtain Longevity!”*]

???
1. Don't describe experimental stuff, people are interested in Science!
2&3. No need to show all the **subtle implementation details** and expose the limitations to your methods
4. **Hierarchy** of experts and non-experts (you are the expert, you define what is what, benchmarks, etc.)
5. Other people to scoop your research ideas, understand how your code actually works instead of why you say it does, or worst of all to understand that **your code doesn’t actually work at all**.

---

# Remember: Reproducibility needs work!

<img src="https://thecodinglove.com/content/038/SLFSVsF.gif">

--

.larger[
- Technical expertise
- Use the right tools, follow *standards*
- Ask for .blue[advice]!
- Research work and Reproducibility practice .green[*balance*]
]

???
Reproducibility (should be easy to achieve) vs Replicability (difficult) argument

---

# .small[Good practises for Computational Reproducibility]

.larger[
- Publish your code (e.g. GitHub) .purple[Barnes (2010)]
- Publish your data (e.g. Zenodo, Figshare)
- Link executable code with data (*CodeOcean*)
- Develop a .blue[culture of reproducibility] .purple[Peng (2011)]
]

![](img/reproducibility_spectrum.png)

.small[Figure from .purple[Peng (2011) *Reproducible Research in Computational Science*]]

???

**Document and test** your code is equally important :)

---

# Example 0: Using the Docker Technology

- Image
- Docker as a Future-proof container of knowledge
- The CoLoMoTo Docker

---
# Example 1: A Reproducible Report in R

- .purple[rtemps]

Use Github and Github pages
1 Figure = 1000 words
Nobody needs to see your code but it needs to be there (button hide)
Cite your References
Make sure your links work
CSS Color boxes + notes for important messages (capture reader's attention)
TOC (always on the left, provides an abstract view of report)

---
# Example 2: Software Engineering concepts in Reproducible Modeling

- .purple[PySB]


---
# Discussion

- .purple[REFLECT] on the way you do science?
- Reproducibility and Responsibility (RRI)
- From Reproducible Reports to actual papers
.  
.  
.

---

class: center, middle

# Thanks!

<img src="https://media.giphy.com/media/XHVmD4RyXgSjd8aUMb/giphy.gif">

----

Slides created with the R package [**xaringan**](https://github.com/yihui/xaringan)

Code for the slides: [https://github.com/bblodfon/r-pres](https://github.com/bblodfon/r-pres)
`r shiny::icon("github")`



